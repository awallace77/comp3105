\documentclass[12pt]{article}

\usepackage{fullpage}
\usepackage{fancybox}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{float} 
\usepackage{multirow}


%%%%%%%%%%%%%% Capsule %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\capsule}[2]{\vspace{0.5em}
  \shadowbox{%
    \begin{minipage}{.90\linewidth}%
      \textbf{#1:}~#2%
    \end{minipage}}
  \vspace{0.5em} }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcounter{ques}
\newenvironment{question}{\stepcounter{ques}{\noindent\bf Question \arabic{ques}:}}{\vspace{5mm}}

\begin{document} 

\begin{center} \Large\bf
COMP 3105 -- Assignment 3 Report\\
-- Fall 2025 -- 
\end{center} 

\begin{center}
{\bf Due:} Sunday November 16, 2025 23:59. \\
Group 51 \\
Andrew Wallace - 101210291\\
Christer Henrysson - 101260693\\[1em]
\end{center}
\textbf{Getting started} \\
Note that Python 3.11 is used for this assignment. Please install requirements using virtual environment via: \\
  \texttt{python3.11 -m venv .venv} \\
  \texttt{source .venv/bin/activate} \\
  \texttt{pip install -r requirements.txt}
\vspace{0.5em}
\newpage 

\section*{Question 1 (4\%) Linear Multi-Class Classifier}
\begin{enumerate}[(a)]
  \item (1\%) Implement a Python function \\
  \texttt{W = minMulDev(X, Y)} \\
  Please see \texttt{A3codes.py} for the implementation of \texttt{W = minMulDev(X, Y)}
  \item (1\%) Implement a Python function \\
  \texttt{Yhat = classify(Xtest, W)} \\
  Please see \texttt{A3codes.py} for the implementation of \texttt{Yhat = classify(Xtest, W)}
  \item (1\%) Implement a Python function \\
  \texttt{acc = calculateAcc(Yhat, Y)} \\
  Please see \texttt{A3codes.py} for the implementation of \texttt{acc = calculateAcc(Yhat, Y)}
  \item (1\%) In this part, you will evaluate your implementation on the synthetic datasets from above.
  The results from the synthetic classification experiment using seed 101210291 report the following training accuracies:
  \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|}
      \hline
      $n$ & Model 1 & Model 2 \\
      \hline
      16 & 0.93125 & 1 \\
      32 & 0.88125 & 0.984375 \\
      64 & 0.86875 & 0.9609375\\
      128 & 0.85390625 & 0.94296875\\
      \hline
    \end{tabular}
    \caption{Training accuracies with different number of training dataset sizes}
    \label{tab:q1_classification_training}
  \end{table}
  
  The results from the synthetic classification experiment using seed 101210291 report the following test accuracies:
  \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|}
      \hline
      $n$ & Model 1 & Model 2 \\
      \hline
      16 & 0.7317 & 0.8963\\
      32 & 0.7928& 0.8857\\
      64 & 0.8228& 0.8976\\
      128 & 0.844& 0.9178\\
      \hline
    \end{tabular}
    \caption{Test accuracies with different number of training dataset sizes}
    \label{tab:q1_classification_test}
  \end{table}

  \[
    W^* = \text{argmin}_W \in \mathbb{R}^{d \times k} \frac{1}{n} \sum_{i = 1}^{n} \log(1_{k}^\text{T} \exp^{W^T x_i}) - y_i^\text{T} W^\text{T} x_i
  \]  
  Our results show that the training for our linear classifier is less accurate for data generated with data model 1 compared to data generated with model 2. This is because the data in model 1 has more overlap compared to model 2. This makes the data classes more difficult to linearly separate. We also see a trend towards lower accuracies as the number of data points increases. Again, this is possibly due to the difficulty of linearly separating classes when there is more overlapping data points that belong to different classes. 
  However, this reduces overfitting in the learned classifier, generalizing better to the test dataset. That is, as the number of data points increases in the test dataset, the accuracies increase due to this generalization in the classifier.
\end{enumerate}

\section*{Question 2 (7\%) Principle Component Analysis}
\begin{enumerate}[(a)]
  \item (1\%) Implement a Python function \\
  \texttt{U = PCA(X, k)} \\
  Please see \texttt{A3codes.py} for the implementation of \texttt{PCA(X, k)}
  \item (0.5\%) Implement a Python function \\
  \texttt{Xproj = projPCA(Xtest, mu, U)}\\
  Please see \texttt{A3codes.py} for the implementation of \texttt{projPCA(Xtest, mu, U)}
  \item (2\%) Implement a Python function \\
  \texttt{A = kernelPCA(X, k, kernel func)}\\
  Please see \texttt{A3codes.py} for the implementation of \texttt{kernelPCA(X, k, kernel func)}
  \item (2\%) Implement a Python function \\
  \texttt{Xproj = projKernelPCA(Xtest, Xtrain, kernel func, A)}\\
  Please see \texttt{A3codes.py} for the implementation of \texttt{projKernelPCA(Xtest, Xtrain, kernel func, A)}
  \item (1\%) In this part, you will evaluate your implementation on the synthetic datasets from above. Implement a Python function\\
  \texttt{train\_acc, test\_acc = synClsExperimentsPCA()}\\
  Please see \texttt{A3codes.py} for the implementation of \texttt{synClsExperimentsPCA()} \\
  The results from the synthetic PCA classification experiment using seed 51 report the following training accuracies:
  \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|}
      \hline
      Dim $k$ & Model 1 & Model 2 \\
      \hline
      1 & 0.8503125 & 0.64242188\\
      2 & 0.85789063 & 0.94179687 \\
      \hline
    \end{tabular}
    \caption{Training accuracies for PCA classification with different dimension sizes}
    \label{tab:q2_classification_training}
  \end{table}
  
  The results from the synthetic PCA classification experiment using seed 51 report the following test accuracies:
  \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|}
      \hline
      Dim $k$ & Model 1 & Model 2 \\
      \hline
      1 & 0.84541 & 0.63417 \\
      2 & 0.83993 & 0.91801 \\
      \hline
    \end{tabular}
    \caption{Test accuracies for PCA classification with different dimension sizes}
    \label{tab:q2_classification_test}
  \end{table}
  \item (0.5\%) Looking at your tables from above, analyze the results and discuss any findings you may have and the possible reason behind them.
\end{enumerate}

\section*{Question 3 (4\%) $k$-means}
\begin{enumerate}[(a)]
  \item (1\%) Implement a Python function \\
  \texttt{Y, U, obj val = kmeans(X, k, max iter=1000)}
  \item (1\%) Implement a Python function \\
  \texttt{Y, U, obj val = repeatKmeans(X, k, n runs=100)}
  \item (1\%) Implement a Python function \\
  \texttt{obj val list = chooseK(X, k candidates=[2,3,4,5,6,7,8,9])}
  \item (2\%) Implement a Python function \\
  \texttt{Xproj = projKernelPCA(Xtest, Xtrain, kernel func, A)}
\end{enumerate}

\section*{References}
 \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
      \hline
      $\lambda$ & Linear & Poly($d{=}2$) & Gauss($\sigma{=}1.0$) \\
      \hline
      0.001 & 0.958 & \textbf{0.978} & 0.493 \\
      0.01  & 0.958 & \textbf{0.978} & 0.493 \\
      0.1   & 0.958 & \textbf{0.978} & 0.493 \\
      \hline
    \end{tabular}
    \caption{Q3(c) average validation accuracies for MNIST (4 vs 9). Best setting: $\lambda{=}0.001$, Poly($d{=}2$).}
    \label{tab:q3_cv}
    \end{table}

\end{document} 
